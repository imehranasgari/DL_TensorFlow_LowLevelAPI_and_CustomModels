{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c918cadb-06a7-430f-92cf-ec2b74f726be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019bf518-f883-446a-8945-57a8ee1801a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fd6fcb-26da-427a-aa6a-57439b4e00ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "california_housing = fetch_california_housing()\n",
    "california_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc77eb57-30f8-4d0d-b64b-cafed39c08af",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train0, X_test, y_train0, y_test = train_test_split(\n",
    "                 california_housing[\"data\"],\n",
    "                 california_housing[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2980735a-2301-4404-a498-a629918577a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train_s = sc.fit_transform(X_train0)\n",
    "X_test_s = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856ae97a-3893-4b28-9eb8-bcda33255719",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(50, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfe331e-d5c8-41f2-8f34-175aaefcdbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mean_squared_error\",\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=[\"mean_absolute_error\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b595c9bc-a97e-42b5-a0f0-a216299efb4c",
   "metadata": {},
   "source": [
    "## custom loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1849c58-3264-4340-ae5d-122185437584",
   "metadata": {},
   "source": [
    "Because we said to avoid using if statements as much as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b209b2a-a52a-4115-8f2e-7a77140fc8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_loss_ (y_true , y_pred):\n",
    "    error = tf.math.abs(y_true - y_pred)\n",
    "    return tf.experimental.numpy.select(condlist=[error<0.1,error<1,error>=1],\n",
    "                                         choicelist=[error,error*2,error**2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981f7bf7-b9c9-43aa-b4ad-ebb25722b96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065d59e9-7bc9-42e8-a30b-8c0419a9cff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=my_loss_,\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=[\"mean_absolute_error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf42c4c-4870-4ec4-adbf-80cdf8201bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_loss2 (t1,t2):\n",
    "    def my_loss (y_true , y_pred):\n",
    "        error = tf.math.abs(y_true - y_pred)\n",
    "        return tf.experimental.numpy.select(condlist=[error<t1,error<t2,error>=t2],\n",
    "                                             choicelist=[error,error*2,error**2])\n",
    "        return my_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eedb6a6-9395-47c8-9370-217503b758cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_loss_2 = my_loss2(0.1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a50667-f8ca-4253-b35b-0aa8910bedb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=my_loss_2,\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=[\"mean_absolute_error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1b1947-2e90-401b-9222-2efa13a07678",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_s, y_train0, epochs=5, validation_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f3258f-4078-414f-b2cb-f9311c9eb362",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('reg_model_my_loss_2.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b2fe99-5dd9-46e8-9018-962ffef4eb48",
   "metadata": {},
   "source": [
    "Here, when calling and loading the model, we treat that internal function as the key—the one that has both the predicted and actual values.\n",
    "And for the value, we consider the outermost function, the one that has hyperparameters.\n",
    "But this approach is not optimal, and the numbers we need to set as hyperparameters get lost, so the correct way is inheritance.\n",
    "We need the model itself to save our hyperparameters, which goes inside\n",
    "* get_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b2840b-e494-4375-b96b-b48d76c48137",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_my_loss_2 = keras.models.load_model('reg_model_my_loss_2.keras',\n",
    "                       custom_objects={'my_loss': my_loss_2\n",
    "                                                # my_loss2 (0.1,1)\n",
    "                                                  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86f708b-106c-4008-9eeb-a7f16f8417a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_my_loss_2.predict(X_test_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6b9ded-0e47-48af-9660-12b37b6a5388",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLoss(keras.losses.Loss):\n",
    "    def __init__(self, t1, t2, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.t1 = t1\n",
    "        self.t2 = t2\n",
    "\n",
    "\n",
    "    def call(self, y_true, y_pred):      \n",
    "        error = tf.abs(y_true - y_pred)\n",
    "        return tf.where(error < self.t1, error,\n",
    "                        tf.where(error < self.t2, error * 2, error ** 2))\n",
    "\n",
    "    def get_config(self):\n",
    "        # تنظیمات والد رو می‌گیریم که چیزی از قلم نیفته\n",
    "        config = super().get_config()\n",
    "        # t1 و t2 رو اضافه می‌کنیم که موقع لود کردن مدل گم نشن\n",
    "        config.update({\"t1\": self.t1,\n",
    "                       \"t2\": self.t2})\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdafb27d-53b1-42f2-8508-1e5d5ae07fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_loss_class =MyLoss(0.1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c200189e-95aa-4de5-9362-452ceb2efe0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=MyLoss(0.1,1),\n",
    "                  # my_loss_class,\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=[\"mean_absolute_error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302dac3a-20ea-4a3b-be83-45a2b0e498af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_s, y_train0, epochs=5, validation_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0390e8fe-0017-401d-b381-3f2e3576e579",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('reg_model_my_loss__class.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a3a7fd-0b36-4db0-acf7-eb0bcf6cb1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_my_loss_class = keras.models.load_model('reg_model_my_loss__class.keras',\n",
    "                       custom_objects={'MyLoss': MyLoss\n",
    "                                                  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1042523d-1b22-45b1-a308-9f129e09323e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_my_loss_class.predict(X_test_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c28c622-bd58-407a-b7b8-1dbd6eb34827",
   "metadata": {},
   "source": [
    "## custom regularizers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9abaf34-f147-4322-bbfb-002796803706",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "class L1RegCustom(tf.keras.Regularizer):\n",
    "    def __init__(self, l1=0.01):\n",
    "        self.l1 = l1\n",
    "\n",
    "    def __call__(self, weight_matrix):\n",
    "        return 0.01 * tf.reduce_sum(tf.abs(weight_matrix))\n",
    "\n",
    "    def get_config(self):\n",
    "        return {'l1': self.l1}\n",
    "\n",
    "layer = tf.keras.layers.Dense(5, input_dim=5,\n",
    "                                 kernel_initializer='ones',\n",
    "                                 kernel_regularizer=L1RegCustom(l1=0.01))\n",
    "\n",
    "tensor = tf.keras.ops.ones(shape=(5, 5))\n",
    "\n",
    "out = layer(tensor)\n",
    "\n",
    "print(layer.losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0314f3e7-dce1-4b80-a991-2a46a51ec5e1",
   "metadata": {},
   "source": [
    "### custom Constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d04024-7942-441f-a6d3-a930e210da23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NonNegative(keras.constraints.Constraint):\n",
    "\n",
    " def __call__(self, w):\n",
    "   return w * tf.keras.ops.cast(ops.greater_equal(w, 0.), dtype=w.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4024ec44-27de-4a85-94fc-d02a07cfbf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.layers.Dense(4, kernel_constraint=NonNegative())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65e2b6a-6816-4749-96b4-d191761a6c9c",
   "metadata": {},
   "source": [
    "## custom Initializer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4548e721-f96c-4277-8224-e87d93867dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleRandomNormal(tf.keras.Initializer):\n",
    "    def __init__(self, mean, stddev):\n",
    "        self.mean = mean\n",
    "        self.stddev = stddev\n",
    "\n",
    "    def __call__(self, shape, dtype=None, **kwargs):\n",
    "        return keras.random.normal(\n",
    "            shape, mean=self.mean, stddev=self.stddev, dtype=dtype\n",
    "        )\n",
    "\n",
    "    def get_config(self):  # To support serialization\n",
    "        return {\"mean\": self.mean, \"stddev\": self.stddev}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e703c606-0cfc-44a5-9d3b-66de7b3857fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ساخت نمونه از Initializer با مقادیر دلخواه\n",
    "custom_initializer = ExampleRandomNormal(mean=0.0, stddev=0.05)\n",
    "\n",
    "# تعریف مدل\n",
    "model = tf.keras.models.Sequential([\n",
    "    layers.Dense(10, input_dim=5, kernel_initializer=custom_initializer),\n",
    "    layers.Dense(1, kernel_initializer=custom_initializer)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8790fa-49cc-4b09-8ca3-aa25e2b64d2d",
   "metadata": {},
   "source": [
    "### custom activation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f061e40e-279d-4902-bb74-06b8c2aea7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.keras.utils.register_keras_serializable()\n",
    "def custom_activation(x):\n",
    "    # ترکیب 70% ReLU و 30% Sigmoid\n",
    "    relu_part = tf.nn.relu(x) * 0.7\n",
    "    sigmoid_part = tf.nn.sigmoid(x) * 0.3\n",
    "    return relu_part + sigmoid_part\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db61665-295c-43f9-add0-c125523aab4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# استفاده در مدل\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, input_dim=5),\n",
    "    tf.keras.layers.Activation(custom_activation),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.fit(tf.random.normal((100, 5)), tf.random.normal((100, 1)), epochs=5, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cb31a7-8f02-4d9c-8714-4339136f16a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomActivation(tf.keras.layers.Layer):\n",
    "    def __init__(self, relu_weight=0.7, sigmoid_weight=0.3, **kwargs):\n",
    "        super(CustomActivation, self).__init__(**kwargs)\n",
    "        self.relu_weight = relu_weight\n",
    "        self.sigmoid_weight = sigmoid_weight\n",
    "\n",
    "    def call(self, inputs):\n",
    "        relu_part = tf.nn.relu(inputs) * self.relu_weight\n",
    "        sigmoid_part = tf.nn.sigmoid(inputs) * self.sigmoid_weight\n",
    "        return relu_part + sigmoid_part\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(CustomActivation, self).get_config()\n",
    "        config.update({\n",
    "            'relu_weight': self.relu_weight,\n",
    "            'sigmoid_weight': self.sigmoid_weight\n",
    "        })\n",
    "        return config\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9512add5-6bb2-4bcb-a3b2-8b5a815be617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# استفاده در مدل\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, input_dim=5),\n",
    "    CustomActivation(relu_weight=0.7, sigmoid_weight=0.3),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.fit(tf.random.normal((100, 5)), tf.random.normal((100, 1)), epochs=5, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0363b64-0390-4b34-a5b1-e58844271db2",
   "metadata": {},
   "source": [
    "## custom metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112e1f81-5f59-4f8c-88b5-192635da93b5",
   "metadata": {},
   "source": [
    "Loss is for the model and doesn’t have much explicit interpretation; it’s mostly used for updating the weights.\n",
    "But we use a metric to understand how well we’ve performed so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf1d457-a831-4271-82e8-5a47f562f6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_metric_r2 (y_true,y_pred):\n",
    "    ss_res = tf.reduce_sum((y_true-y_pred)**2)\n",
    "    ss_total = tf.reduce_sum((y_true-tf.reduce_mean(y_true))**2)\n",
    "    r2 = 1 - (ss_res/ss_total+1e-6)\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce241f2a-32d1-4632-822d-6f175486cbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=MyLoss(0.1,1),\n",
    "                  # my_loss_class,\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=[my_metric_r2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c5450b-2ad2-4854-b095-8d2fcadf32e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_s, y_train0, epochs=5, validation_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd994b22-cccd-4ed4-b270-04e2e06db6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedMAE(tf.keras.metrics.Metric):\n",
    "    def __init__(self, weight=1.0, name='weighted_mae', **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.weight = weight\n",
    "        self.total = self.add_weight(name='total', initializer='zeros')\n",
    "        self.count = self.add_weight(name='count', initializer='zeros')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        # خطای مطلق با وزن محاسبه می‌شه\n",
    "        error = tf.abs(y_true - y_pred) * self.weight\n",
    "        if sample_weight is not None:\n",
    "            error *= sample_weight\n",
    "        self.total.assign_add(tf.reduce_sum(error))\n",
    "        self.count.assign_add(tf.cast(tf.size(y_true), tf.float32))\n",
    "\n",
    "    def result(self):\n",
    "        # میانگین وزن‌دار خطا\n",
    "        return self.total / self.count\n",
    "\n",
    "    def reset_states(self):\n",
    "        # ریست متغیرها\n",
    "        self.total.assign(0.0)\n",
    "        self.count.assign(0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19efb9ac-841f-478b-a78b-25652e49beca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# مدل با متریک\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, input_dim=5),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='mse', metrics=[WeightedMAE(weight=1.5)])\n",
    "model.fit(tf.random.normal((100, 5)), tf.random.normal((100, 1)), epochs=5, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41583a0c-b53e-4834-9ee8-589cb10452c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class BinaryTruePositives(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='binary_true_positives', **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.true_positives = self.add_variable(\n",
    "            shape=(),\n",
    "            initializer='zeros',\n",
    "            name='true_positives'\n",
    "        )\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        # تبدیل به نوع بولین\n",
    "        y_true = tf.keras.ops.cast(y_true, \"bool\")\n",
    "        y_pred = tf.keras.ops.cast(y_pred, \"bool\")\n",
    "\n",
    "        # محاسبه True Positives\n",
    "        values = tf.keras.ops.logical_and(\n",
    "            tf.keras.ops.equal(y_true, True), tf.keras.ops.equal(y_pred, True))\n",
    "        values = tf.keras.ops.cast(values, self.dtype)\n",
    "        if sample_weight is not None:\n",
    "            sample_weight = tf.keras.ops.cast(sample_weight, self.dtype)\n",
    "            sample_weight = tf.keras.ops.broadcast_to(\n",
    "                sample_weight, tf.keras.ops.shape(values))\n",
    "            values = tf.keras.ops.multiply(values, sample_weight)\n",
    "        self.true_positives.assign(self.true_positives + tf.keras.ops.sum(values))\n",
    "\n",
    "    def result(self):\n",
    "        return self.true_positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027bd280-151d-473f-8ba9-d05a40b72491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# مدل با متریک\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, input_dim=5),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='mse', metrics=[BinaryTruePositives()])\n",
    "model.fit(tf.random.normal((100, 5)), tf.random.normal((100, 1)), epochs=5, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1178ea-41dc-4864-bcb9-47d8c7ee6b29",
   "metadata": {},
   "source": [
    "## custom layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b72a582-6480-4735-b290-5abfa8011520",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDense(tf.keras.layers.Layer):\n",
    "    def __init__(self,unit=36):\n",
    "        super(SimpleDense,self).__init__()\n",
    "        self.unit = unit\n",
    "\n",
    "    def build(self,input_shape):\n",
    "        w_init = tf.random_normal_initializer()\n",
    "        self.w = tf.Variable(initial_value = w_init(shape=(input_shape[-1],self.unit),dtype='float32'),\n",
    "                            trainable=True)\n",
    "\n",
    "        b_init = tf.zeros_initializer()\n",
    "        # ویرگول داخل شیپ صرفا برای اینه که تاپل بشه\n",
    "        self.b = tf.Variable(initial_value = b_init(shape=(self.unit,),dtype='float32'),\n",
    "                            trainable=True)\n",
    "\n",
    "    def call(self, inputs):  # Defines the computation from inputs to outputs\n",
    "      return tf.matmul(inputs, self.w) + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24992888-1e53-439a-a249-21aba130a61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiates the layer.\n",
    "linear_layer = SimpleDense(4)\n",
    "\n",
    "# This will also call `build(input_shape)` and create the weights.\n",
    "y = linear_layer(tf.ones((2, 2)))\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27472b51-8d52-49be-bd07-b0e3ce95fe7e",
   "metadata": {},
   "source": [
    "Here, we want to use a combination of our own custom layers.\n",
    "For example, we’re going to use them several times, and each time we’ll set up this sequence again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477a3219-56cc-4b2a-99ad-f950451f8d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLinear(tf.keras.layers.Layer):\n",
    "    def __init__(self,unit=36):\n",
    "        super(MyLinear,self).__init__()\n",
    "        self.unit = unit\n",
    "\n",
    "    def build(self,input_shape):\n",
    "        self.w = self.add_weight(shape=(input_shape[-1],self.unit),\n",
    "                                 initializer='random_normal',\n",
    "                                 trainable=True)\n",
    "        \n",
    "        # ویرگول داخل شیپ صرفا برای اینه که تاپل بشه\n",
    "        self.b = self.add_weight(shape=(self.unit,),\n",
    "                                 initializer='zeros',\n",
    "                                 trainable=True)\n",
    "\n",
    "    def call(self, inputs):  # Defines the computation from inputs to outputs\n",
    "      return tf.matmul(inputs, self.w) + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0219f37-f08e-4637-8deb-48326128f3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(MyBlock,self).__init__()\n",
    "        self.lin1 = MyLinear(50)\n",
    "        self.lin2 = MyLinear(100)\n",
    "        self.lin3 = MyLinear(100)\n",
    "        self.lin4 = MyLinear(100)\n",
    "    def call(self,input_):\n",
    "        x = self.lin1(input_)\n",
    "        x = tf.nn.relu(x)\n",
    "        \n",
    "        x = self.lin2(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        \n",
    "        x = self.lin3(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        \n",
    "        output = self.lin4(x)\n",
    "        \n",
    "        '''\n",
    "        به قسمت زیر توجه کن که با این حرکت می شود در مدل خودمون یک لاس جدید تعریف کنیم که به لاس قبلی اضافه شود\n",
    "        از add_loss\n",
    "        می توان در خود لایه استفاده کرد\n",
    "        '''\n",
    "        loss_ = tf.reduce_mean(output) /2\n",
    "        self.add_loss(loss_)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07887e48-ce06-42c9-a1c9-29a71960085b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    MyBlock(),\n",
    "    MyBlock(),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f09929-ddbc-48a5-81cc-81fd16304a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mean_squared_error\",\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=[\"mean_absolute_error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e421de35-07df-447c-957c-e05a3a2066e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_s, y_train0, epochs=5, validation_split=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f1a1cb-225f-485a-8857-16070851cd7e",
   "metadata": {},
   "source": [
    "## Gradient Tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438b27be-fd2d-452b-aec8-7fd368227c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable(6.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d45f33-9452-4f66-b0ae-a405b86612ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as g:\n",
    "    y = x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535d5c76-50c5-4d75-b82d-e9d94f7edb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dy_dx = g.gradient(y,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147e0be3-7941-417c-896e-61d1acd437e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dy_dx.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a107d2-208d-4f16-899f-ec3cac93e6e4",
   "metadata": {},
   "source": [
    "But we can only show it the equations once and pass the numbers through, and after that, it’s gone. That’s why we need to do something else so that it gets saved and isn’t lost.\n",
    "* persistent = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd40aa48-f14d-4c2a-94ff-f0363db2f688",
   "metadata": {},
   "outputs": [],
   "source": [
    "wight =tf.Variable(tf.random.normal((4,3)) )\n",
    "bias = tf.Variable(tf.zeros(3, dtype = tf.float32))\n",
    "x = np.array([[1.,2.,3.,4.]] , dtype = np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a264086-7e10-49f7-ae33-e1300e525249",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.GradientTape(persistent=True) as g:\n",
    "    y = tf.matmul(x,wight) + bias\n",
    "    loss = tf.reduce_mean(y**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3755e572-1337-4b8f-baef-588d90f9ea6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wight_grad , bias_grad = g.gradient(loss,[wight,bias])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac43dcc-d681-4638-ae95-220bcc7a290d",
   "metadata": {},
   "source": [
    "You should be careful — if it’s a constant, or in other words a tensor, it won’t work correctly, and it must be a variable. However, even if a variable is added to a number, it becomes a constant.\n",
    "Look at the bias now..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ce9eef-cc86-4673-bd28-4d436190dfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "wight =tf.Variable(tf.random.normal((4,3)) )\n",
    "bias = tf.Variable(tf.zeros(3, dtype = tf.float32)) + 10\n",
    "x = np.array([[1.,2.,3.,4.]] , dtype = np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241f3ed7-11d5-4aa2-993e-a35bcb087e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape(persistent=True) as g:\n",
    "    y = tf.matmul(x,wight) + bias\n",
    "    loss = tf.reduce_mean(y**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746b8ad6-0e63-4ce9-8cbd-41b538dfdec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "wight_grad , bias_grad = g.gradient(loss,[wight,bias])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c5a19c-9ef3-4660-9924-68541cebed66",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1eac17-aeb9-4e00-b75f-55d346d5cba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "wight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d801afc-53ed-410f-a1af-6e6c6bbf3d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf366177-b795-4c97-b4ba-807b3a7d5859",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(bias_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d369ec-fa4f-44ad-873d-1b4e79fe7f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(wight_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da7c477-def5-4de0-9a76-9809e0a7f2e3",
   "metadata": {},
   "source": [
    "## به بیان دیگر"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f18aff-f20a-4045-b791-3d401a27555a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = tf.Variable(4.0)\n",
    "x2 = tf.Variable(4.0,trainable =False)\n",
    "x3 = tf.Variable(4.0) *1.05\n",
    "x4 = tf.constant(4.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eddc54d-0d14-4661-80a1-fc3f8d71bf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape(persistent=True) as g:\n",
    "    y = x1**1 + x2**2 + x3**3 + x4**4  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e199f20-077d-4d38-b473-b9098a77c5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dz_dx = g.gradient(y , [x1,x2,x3,x4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185f9508-17af-4677-bb93-c4b3b16b02aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# چاپ گرادیان‌ها\n",
    "for i, dz in enumerate(dz_dx):\n",
    "    print(f\"Gradient w.r.t x{i+1}: {dz}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e54c2f-d7a9-4f42-a180-941f18fad9a1",
   "metadata": {},
   "source": [
    "حالا برای اینکه از اعداد ثابت هم بتوانیم مشتق بگیریم"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cb839e-6154-42bb-b01a-d79b9b483255",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape(watch_accessed_variables=False) as g:\n",
    "    g.watch(x4)\n",
    "    y = x4 **3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9b0140-f8d1-431d-b8fe-f3120bd62886",
   "metadata": {},
   "outputs": [],
   "source": [
    "dy_dx = g.gradient(y,x4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3696e432-bf11-4f74-8f3e-4e3d0e7acbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dy_dx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ef5356-37cb-4e36-9ce1-27e92cd70b92",
   "metadata": {},
   "source": [
    "ما از خود لایه ها هم می توانیم به صورت مستقیم هم استفاده کنیم "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8afbce4-d58b-412c-b2bf-19107fd3a700",
   "metadata": {},
   "outputs": [],
   "source": [
    "den = tf.keras.layers.Dense(5,activation='elu')\n",
    "x1 = tf.constant([[1.,2.,3.,4.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ede925e-e3ec-474e-a5de-4158c733e1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as g:\n",
    "    y = den(x1)\n",
    "    loss = tf.reduce_mean(y **2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dda3483-64a6-427f-96f8-41486952a019",
   "metadata": {},
   "outputs": [],
   "source": [
    "dloss_dw = g.gradient(loss, den.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a4ab4d-535c-4687-9acf-efb8c8c45fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "dloss_dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9770b909-55c6-473b-b4ff-d59bdc74a30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train0, y_train0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6d219a-d460-407a-9e8e-de84a41ee4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_s.shape, y_train0.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea11bba-6d2b-4bbd-a722-72fc3211659f",
   "metadata": {},
   "source": [
    "بچ 30 تایی یعنی به صورت زیر و ایپاک هم یعنی چند بار از روی خودش بگذره دیگه"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6fab00-69fc-4398-bf57-33a161ec1d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "15480/30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c311163-6910-4a68-8a05-9280c833f7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935ad8b2-73dd-414a-8a1c-e9c7abc4e045",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = tf.data.Dataset.from_tensor_slices((X_train_s, y_train0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213adbf9-bee7-4943-902b-5d86d0282676",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_ = train_data.shuffle(buffer_size=len(y_train0)).batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7bc02d-6ad6-487f-9bea-7feb55e76cd9",
   "metadata": {},
   "source": [
    "تبدیل شده به همین تعداد بچ های شافل شده که در بالا نشان دادم"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ca7e9a-33b8-4538-96c9-95d14ae27df9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i , (x, y) in enumerate(train_data_):\n",
    "  print(i+1,x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee377e3e-2b25-4029-8905-4b50028bfaeb",
   "metadata": {},
   "source": [
    "## training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167070f0-a724-45d0-b76f-be739d1cf2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(50, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a92302-f4f4-4833-9fad-ee21aaba98cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.MeanSquaredError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8909a5bc-291f-4521-a566-e99d9a2b0f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimazer_ = tf.keras.optimizers.SGD(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa56a99-43e3-415c-92ca-948a397a5338",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mae = tf.keras.metrics.MeanAbsoluteError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea105f76-b159-42ae-8c07-477db193840e",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs =10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1d3749-ddab-4e1b-8c57-216bf5c88500",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    # Now the next for loop is for the batches\n",
    "    for bach_i, (x_train, y_train) in enumerate(train_data_):\n",
    "        with tf.GradientTape() as g:\n",
    "            model_out = model(x_train, training=True)\n",
    "            loss_val = loss_fn(y_train, model_out)\n",
    "            \n",
    "        dloss_dmodel = g.gradient(loss_val, model.trainable_weights)\n",
    "        \n",
    "        # Now we have obtained the derivatives, and here is where the weights should be updated\n",
    "        optimazer_.apply_gradients(zip(dloss_dmodel, model.trainable_weights))\n",
    "\n",
    "        # Now we want our metric to be updated each time it runs\n",
    "        train_mae.update_state(y_train, model_out)\n",
    "        \n",
    "        if bach_i % 100 == 0:\n",
    "            print('training loss', float(loss_val))\n",
    "            \n",
    "    # These metrics are stored all at once; with this operation, we display them at each epoch\n",
    "    train_mae_val = train_mae.result()\n",
    "    print('train mae', float(train_mae_val))\n",
    "    # Here, since we don’t want previous epochs to be involved and want each epoch\n",
    "    # to have its own metric calculation separately, we reset it\n",
    "    train_mae.reset_state()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3fd263-170b-4f22-939d-c6b601922c78",
   "metadata": {},
   "source": [
    "## قابلیت های tfdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38501df-67a4-4e34-9f60-3bc9f0e45c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "dataset = tf.data.Dataset.range(100)\n",
    "dataset = dataset.filter(lambda x: x < 5)\n",
    "result = list(dataset.as_numpy_iterator())\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423966c6-3114-47ea-9425-be0cae4f1b51",
   "metadata": {},
   "source": [
    "## tf.data capabilities\n",
    "Storing data in a binary and compact form for tf.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f268110-7c57-4c01-9f32-5f1431e5efc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.io.TFRecordWriter('data_test_recored') as t:\n",
    "    t.write(b'deep learning')\n",
    "    t.write(b'python')\n",
    "    t.write(b'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e244c3f5-aed4-4067-8890-0c8632147b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_ = ['data_test_recored']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cd7051-b8e5-4299-8d6d-034dc081cb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data_test  = tf.data.TFRecordDataset(file_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b8dda0-9b37-43c0-bf64-8b3dd1d01bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in my_data_test:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454cf3e9-093d-4a09-9f31-da08800d19cc",
   "metadata": {},
   "source": [
    "tensorflow teranform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cd8f3c-9145-40a7-adba-5d68457d9d8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf] *",
   "language": "python",
   "name": "conda-env-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
